# 前言

以前，绝大多数的机器学习和信号处理技术都是利用**浅层结构**，这些结构包含最多一到两层非线性特征变换。浅层结构包括：**高斯混合模型(GMM)**、**线性或非线性动力系统**、**条件随机场(CRF)**、**最大熵模型(MaxEnt)**、**支持向量机(SVM)**、**逻辑回归(LR)**、**核回归以及多层感知机(MLP)**(包括只包含一个隐层的极限学习器)。

浅层结构的优点：简单问题与限制较多的问题上效果明显；缺点：建模与表示能力有限，很难甚至无法解决复杂问题。

### 深度学习的三次觉醒

20世纪40-60年代：控制论。第一次模拟与训练了单个神经元。

20世纪80-90年代中期：联结主义方法兴起。诞生了使用反向传播算法训练包含1-2个隐含层的神经网络。

2006-现今：深度学习大爆发。

**导火索**：Hinton在2006年介绍了一种无监督学习算法：深度置信网络(Deep Belief Network, DBN)。

DBN由一组受限玻尔兹曼机(RBMs)堆叠而成，核心部分是贪婪的、逐层学习的算法。利用DBN初始化网络，然后利用反向传播算法微调网络，最终得到了很好的效果。**使用DBN初始化DNN，这个网络可以叫做DBN-DNN**。

DBN优点：使用未标注的数据；可以看做是一个概率生成模型。

**根本原因**：硬件运算速度的提升。

DNN中多隐层的使用极大的提高了建模能力，所以在实际中往往使用又宽又深的网络，然而这样的网络对计算性能又有极高的要求。

对DNN的预训练，除了DBN以外，还可以使用降噪自编码器、压缩自编码器、稀疏编码对称机(SESM)等均可达到很好的效果。如果是拥有标签的数据，还可以使用判别式预训练来完成，而且效果比无监督的预训练算法要好。

# 定义

**深度学习**（英语：deep learning）是机器学习拉出的分支，它试图使用包含复杂结构或由多重非线性变换构成的多个处理层对数据进行高层抽象的算法。深度学习主要研究的是广义的人工神经网络(Artificial Neural Network, ANN)(除了ANN外，还包括层次概率模型、特征学习等)，所以深度学习通常也指代ANN。人工神经网络，顾名思义，即为大脑神经系统的仿生学。

深度学习可以利用三元分类法分为：监督学习、无监督学习、半监督学习。

深度学习基础算法包括：

1. **深度置信网络(Deep Belief Network, DBN)**: 由多层随机隐变量组成的概率生成式模型，最高两层之间由无向对称边连接，低层接受来自上一层的自顶向下的有向边。
2. **玻尔兹曼机(Boltzmann Machine, BM)**: 具有对称型连接的网络，它由于神经元相似的单元构成，能够控制随机决策开关的闭合。
3. **受限玻尔兹曼机(Restricted Boltzmann Machine, RBM)**: 一种特殊的BM，它由一个可见单元层和一个隐单元层组成，而且每条边必须连接一个可见单元和一个隐单元，同层单元之间无连接。
4. **深度神经网络(Deep Neural Network, DNN)**: 一种具有多个隐层的多层感知器，层与层之间是全连接的。
5. **深度自编码器(Deep Autoencoder)**: 一种“判别式”DNN，它的目标输出是数据本身。是一种无监督学习模型。当以除噪准则训练深度自编码器时，它也可看做是一个生成模型并能从中采样。
6. **分布式表征(Distributed Representation)**: 观测数据的内部表达，以众多隐因子之间的相互作用来建模。从其它因子结构学习到的某个因子可以很好地推广到新的结构。

# 了解人类大脑的学习过程

大脑的认知、思考、记忆等功能均是建立在很多神经元细胞互相连接的基础上。人刚出生时，大脑内的神经元之间的连接相对较少，这时候我们只会做哭泣、呼吸、吞咽等基本活动。随着我们对外界的接触越来越多，我们学会了走路、规律发声等，这时候大脑内的神经元之间形成了更多的连接。在我们与环境的交互过程中，感觉神经元收集外界的刺激，并传递给联络神经元对信号进行变换，最后信号传递给运动神经元并做出反应，在这一过程中，中间神经元会不断的变换神经元之间的连接与连接强度，逐步形成形成稳定的连接。

### 生物意义上的神经元

“神经元”就是“神经细胞”。神经元的主要结构包括：胞体和突触(突触一般分为树突与轴突。树突呈树状，用于接收其它神经元的信息并传递给胞体；轴突是一个细长的突起，用于传递信息给下一个神经元)。

神经元的两个主要特性：**兴奋性**和**传导性**。当刺激强度达到某一阈值(刺激可以积累)时，神经冲动会在瞬间以最大强度传导出去。

在人的成长学习过程中，神经元之间会逐步建立或断开某些连接：外界的刺激会传递给整个神经网络，并影响网络的结构，同时网络结构的变化又会影响我们队外界的判断。这就是我们学习的过程。

### 神经网络

神经网络是由很多的神经元构成的网络，在对神经元的研究中发现：神经网络是分层结构的，每一层有一定数量的神经元构成，层与层之间有着紧密的联系。通过多层的叠加，神经网络可以模拟任意复杂的过程。

如果把人的行为用函数来表示，通过数以百亿计的神经元的不同互联可以模拟几乎任意的函数过程。为什么可以呢？想想泰勒级数展开后就可以用比原函数更简单的多项式相加来逼近某一个函数或者计算机底层利用0和1构建了我们复杂的计算操作。每一个神经元所能产生的变换是很简单的，但是它们组合之后的可能性确实无群无尽的。

# 深度学习与大脑学习的关系

仿造大脑的神经元的结构，设计了人工神经元。当有刺激到来时可以接收并转换(线性转换或者非线性转换)，然后传导出去。

仿造神经网络的多层次结构，我们设计了多层次结构。每一层由一定数量人工神经元构成，每一层与相近的层全连接(上一层的每一个人工神经元分别于下一层的每一个神经元连接在一起)。





